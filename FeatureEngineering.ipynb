{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Notebook 3: Feature Engineering & Aggregation\n",
        "* Goal: Transform the clean df_clean (reactor-level) data into aggregated time-series datasets."
      ],
      "metadata": {
        "id": "rxW4lHTkqKFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 1: Filter for 'Operational' Reactors\n",
        "\n",
        "For our demand analysis, we only care about reactors that are \"Operational\" (i.e., consuming fuel). We'll create a new, filtered DataFrame for this."
      ],
      "metadata": {
        "id": "PW_wtVwRqshG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter df_clean to only include operational reactors\n",
        "df_operational = df_clean[df_clean['Status'] == 'Operational'].copy()\n",
        "\n",
        "print(\"Created 'df_operational' DataFrame with 'Operational' reactors only.\")\n",
        "print(f\"Total rows in df_clean: {len(df_clean)}\")\n",
        "print(f\"Operational rows in df_operational: {len(df_operational)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuGDcnGAqs0K",
        "outputId": "717a3cc5-2143-48b5-eb72-99cd3bceb424"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 'df_operational' DataFrame with 'Operational' reactors only.\n",
            "Total rows in df_clean: 20830\n",
            "Operational rows in df_operational: 13632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 2: Create Core Demand Time Series\n",
        "\n",
        "Now we'll group the operational data by Global, National, and Technology to create our primary datasets."
      ],
      "metadata": {
        "id": "VnQWqDzsqtJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Global Demand Time Series (by Year)\n",
        "global_demand_ts = df_operational.groupby('Year')['Thermal Capacity, MWt'].sum().reset_index()\n",
        "global_demand_ts = global_demand_ts.rename(columns={'Thermal Capacity, MWt': 'Total Thermal Capacity, MWt'})\n",
        "\n",
        "# 2. National Demand Time Series (by Country, Year)\n",
        "national_demand_ts = df_operational.groupby(['Country', 'Year'])['Thermal Capacity, MWt'].sum().reset_index()\n",
        "national_demand_ts = national_demand_ts.rename(columns={'Thermal Capacity, MWt': 'Total Thermal Capacity, MWt'})\n",
        "\n",
        "# 3. Technology Demand Time Series (by Type, Year)\n",
        "tech_demand_ts = df_operational.groupby(['Type', 'Year'])['Thermal Capacity, MWt'].sum().reset_index()\n",
        "tech_demand_ts = tech_demand_ts.rename(columns={'Thermal Capacity, MWt': 'Total Thermal Capacity, MWt'})\n",
        "\n",
        "print(\"Created global, national, and technology time-series DataFrames.\")\n",
        "print(\"\\nGlobal Demand Head:\")\n",
        "print(global_demand_ts.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDclqsjdqtSt",
        "outputId": "d22ec889-c2a3-4fc3-bcb4-b9212533c05c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created global, national, and technology time-series DataFrames.\n",
            "\n",
            "Global Demand Head:\n",
            "   Year  Total Thermal Capacity, MWt\n",
            "0  1969                         4755\n",
            "1  1970                        11851\n",
            "2  1971                        17942\n",
            "3  1972                        32262\n",
            "4  1973                        50505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 3: Create Pipeline Analysis Time Series\n",
        "\n",
        "For this, we need to use the full df_clean to see all statuses (\"Operational\", \"Under Construction\", etc.). We will count the unique reactors in each category per year."
      ],
      "metadata": {
        "id": "EdJULOAGq-g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Year and Status, then count the number of unique reactors\n",
        "pipeline_status_ts = df_clean.groupby(['Year', 'Status'])['Reactor name'].nunique().reset_index()\n",
        "pipeline_status_ts = pipeline_status_ts.rename(columns={'Reactor name': 'Reactor Count'})\n",
        "\n",
        "print(\"Created pipeline status time-series DataFrame.\")\n",
        "print(pipeline_status_ts.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtV3Ltm0q-04",
        "outputId": "5053c541-4222-4616-ad28-1a6f4de91227"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created pipeline status time-series DataFrame.\n",
            "   Year              Status  Reactor Count\n",
            "0     0  Under Construction             63\n",
            "1  1954  Permanent Shutdown              1\n",
            "2  1955  Permanent Shutdown              1\n",
            "3  1956  Permanent Shutdown              2\n",
            "4  1957  Permanent Shutdown              5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 4: Save All Aggregated Datasets\n",
        "\n",
        "Finally, we'll save all our new DataFrames to CSV files. These files will be the sources for all our future notebooks (4, 5, 6, 7, and 8)."
      ],
      "metadata": {
        "id": "IAdDgVs9q_qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all the new dataframes to CSV\n",
        "global_demand_ts.to_csv('global_demand_ts.csv', index=False)\n",
        "national_demand_ts.to_csv('national_demand_ts.csv', index=False)\n",
        "tech_demand_ts.to_csv('tech_demand_ts.csv', index=False)\n",
        "pipeline_status_ts.to_csv('pipeline_status_ts.csv', index=False)\n",
        "\n",
        "# Also create and save the secondary electricity proxy\n",
        "global_electricity_ts = df_operational.groupby('Year')['Electricity Supplied, GW.h'].sum().reset_index()\n",
        "global_electricity_ts.to_csv('global_electricity_ts.csv', index=False)\n",
        "\n",
        "print(\"\\nNotebook 3 complete. All aggregated datasets saved to CSV files:\")\n",
        "print(\"- global_demand_ts.csv\")\n",
        "print(\"- national_demand_ts.csv\")\n",
        "print(\"- tech_demand_ts.csv\")\n",
        "print(\"- pipeline_status_ts.csv\")\n",
        "print(\"- global_electricity_ts.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxTxpSeMq_yr",
        "outputId": "685b81b4-bb9d-4d9c-d266-3f1b172cecc8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Notebook 3 complete. All aggregated datasets saved to CSV files:\n",
            "- global_demand_ts.csv\n",
            "- national_demand_ts.csv\n",
            "- tech_demand_ts.csv\n",
            "- pipeline_status_ts.csv\n",
            "- global_electricity_ts.csv\n"
          ]
        }
      ]
    }
  ]
}